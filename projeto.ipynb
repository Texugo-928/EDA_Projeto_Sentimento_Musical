{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando a Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = 'muse_v3.csv'\n",
    "dados = pd.read_csv(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendendo a Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90001, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90001 entries, 0 to 90000\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   lastfm_url              90001 non-null  object \n",
      " 1   track                   90001 non-null  object \n",
      " 2   artist                  90001 non-null  object \n",
      " 3   seeds                   90001 non-null  object \n",
      " 4   number_of_emotion_tags  90001 non-null  int64  \n",
      " 5   valence_tags            90001 non-null  float64\n",
      " 6   arousal_tags            90001 non-null  float64\n",
      " 7   dominance_tags          90001 non-null  float64\n",
      " 8   mbid                    61217 non-null  object \n",
      " 9   spotify_id              61630 non-null  object \n",
      " 10  genre                   83362 non-null  object \n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastfm_url</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>seeds</th>\n",
       "      <th>number_of_emotion_tags</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>mbid</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.last.fm/music/eminem/_/%2527till%2...</td>\n",
       "      <td>'Till I Collapse</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>6</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>5.273125</td>\n",
       "      <td>5.690625</td>\n",
       "      <td>cab93def-26c5-4fb0-bedd-26ec4c1619e1</td>\n",
       "      <td>4xkOaSrkexMciUUogZKVTS</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.last.fm/music/metallica/_/st.%2banger</td>\n",
       "      <td>St. Anger</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>8</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>5.833000</td>\n",
       "      <td>5.427250</td>\n",
       "      <td>727a2529-7ee8-4860-aef6-7959884895cb</td>\n",
       "      <td>3fOc9x06lKJBhz435mInlH</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.last.fm/music/rick%2bross/_/speedi...</td>\n",
       "      <td>Speedin'</td>\n",
       "      <td>Rick Ross</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>1</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3Y96xd4Ce0J47dcalLrEC8</td>\n",
       "      <td>rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.last.fm/music/m.i.a./_/bamboo%2bbanga</td>\n",
       "      <td>Bamboo Banga</td>\n",
       "      <td>M.I.A.</td>\n",
       "      <td>['aggressive', 'fun', 'sexy', 'energetic']</td>\n",
       "      <td>13</td>\n",
       "      <td>6.555071</td>\n",
       "      <td>5.537214</td>\n",
       "      <td>5.691357</td>\n",
       "      <td>99dd2c8c-e7c1-413e-8ea4-4497a00ffa18</td>\n",
       "      <td>6tqFC1DIOphJkCwrjVzPmg</td>\n",
       "      <td>hip-hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.last.fm/music/dope/_/die%2bmf%2bdie</td>\n",
       "      <td>Die MF Die</td>\n",
       "      <td>Dope</td>\n",
       "      <td>['aggressive']</td>\n",
       "      <td>7</td>\n",
       "      <td>3.771176</td>\n",
       "      <td>5.348235</td>\n",
       "      <td>5.441765</td>\n",
       "      <td>b9eb3484-5e0e-4690-ab5a-ca91937032a5</td>\n",
       "      <td>5bU4KX47KqtDKKaLM4QCzh</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lastfm_url             track  \\\n",
       "0  https://www.last.fm/music/eminem/_/%2527till%2...  'Till I Collapse   \n",
       "1  https://www.last.fm/music/metallica/_/st.%2banger         St. Anger   \n",
       "2  https://www.last.fm/music/rick%2bross/_/speedi...          Speedin'   \n",
       "3  https://www.last.fm/music/m.i.a./_/bamboo%2bbanga      Bamboo Banga   \n",
       "4    https://www.last.fm/music/dope/_/die%2bmf%2bdie        Die MF Die   \n",
       "\n",
       "      artist                                       seeds  \\\n",
       "0     Eminem                              ['aggressive']   \n",
       "1  Metallica                              ['aggressive']   \n",
       "2  Rick Ross                              ['aggressive']   \n",
       "3     M.I.A.  ['aggressive', 'fun', 'sexy', 'energetic']   \n",
       "4       Dope                              ['aggressive']   \n",
       "\n",
       "   number_of_emotion_tags  valence_tags  arousal_tags  dominance_tags  \\\n",
       "0                       6      4.550000      5.273125        5.690625   \n",
       "1                       8      3.710000      5.833000        5.427250   \n",
       "2                       1      3.080000      5.870000        5.490000   \n",
       "3                      13      6.555071      5.537214        5.691357   \n",
       "4                       7      3.771176      5.348235        5.441765   \n",
       "\n",
       "                                   mbid              spotify_id    genre  \n",
       "0  cab93def-26c5-4fb0-bedd-26ec4c1619e1  4xkOaSrkexMciUUogZKVTS      rap  \n",
       "1  727a2529-7ee8-4860-aef6-7959884895cb  3fOc9x06lKJBhz435mInlH    metal  \n",
       "2                                   NaN  3Y96xd4Ce0J47dcalLrEC8      rap  \n",
       "3  99dd2c8c-e7c1-413e-8ea4-4497a00ffa18  6tqFC1DIOphJkCwrjVzPmg  hip-hop  \n",
       "4  b9eb3484-5e0e-4690-ab5a-ca91937032a5  5bU4KX47KqtDKKaLM4QCzh    metal  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastfm_url</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>seeds</th>\n",
       "      <th>number_of_emotion_tags</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>mbid</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>https://www.last.fm/music/gaby%2bhoffmann%2b%2...</td>\n",
       "      <td>Battle</td>\n",
       "      <td>Gaby Hoffmann &amp; Jay Duplass</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>1</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>https://www.last.fm/music/omar%2brodriguez-lop...</td>\n",
       "      <td>Hands Tied to the Roots of a Hemorrhage</td>\n",
       "      <td>Omar Rodriguez-Lopez</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>4</td>\n",
       "      <td>5.797887</td>\n",
       "      <td>4.132254</td>\n",
       "      <td>5.570563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>progressive rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>https://www.last.fm/music/ace%2bwhite/_/crookf...</td>\n",
       "      <td>Crookfield Zoo</td>\n",
       "      <td>Ace White</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>1</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>https://www.last.fm/music/second%2bchyld/_/tra...</td>\n",
       "      <td>Transparent (Full Version)</td>\n",
       "      <td>Second Chyld</td>\n",
       "      <td>['transparent']</td>\n",
       "      <td>1</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000</th>\n",
       "      <td>https://www.last.fm/music/message%2bto%2bbears...</td>\n",
       "      <td>Unfold</td>\n",
       "      <td>Message To Bears</td>\n",
       "      <td>['translucent']</td>\n",
       "      <td>2</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>1.405000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>247179b0-af1f-4c2b-b4fe-751070d1c0cc</td>\n",
       "      <td>14BYEOeRb3jzglJmKX8eM2</td>\n",
       "      <td>ambient</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lastfm_url  \\\n",
       "89996  https://www.last.fm/music/gaby%2bhoffmann%2b%2...   \n",
       "89997  https://www.last.fm/music/omar%2brodriguez-lop...   \n",
       "89998  https://www.last.fm/music/ace%2bwhite/_/crookf...   \n",
       "89999  https://www.last.fm/music/second%2bchyld/_/tra...   \n",
       "90000  https://www.last.fm/music/message%2bto%2bbears...   \n",
       "\n",
       "                                         track                       artist  \\\n",
       "89996                                   Battle  Gaby Hoffmann & Jay Duplass   \n",
       "89997  Hands Tied to the Roots of a Hemorrhage         Omar Rodriguez-Lopez   \n",
       "89998                           Crookfield Zoo                    Ace White   \n",
       "89999               Transparent (Full Version)                 Second Chyld   \n",
       "90000                                   Unfold             Message To Bears   \n",
       "\n",
       "                 seeds  number_of_emotion_tags  valence_tags  arousal_tags  \\\n",
       "89996  ['transparent']                       1      5.370000      3.450000   \n",
       "89997  ['transparent']                       4      5.797887      4.132254   \n",
       "89998  ['transparent']                       1      5.370000      3.450000   \n",
       "89999  ['transparent']                       1      5.370000      3.450000   \n",
       "90000  ['translucent']                       2      3.340000      1.405000   \n",
       "\n",
       "       dominance_tags                                  mbid  \\\n",
       "89996        5.330000                                   NaN   \n",
       "89997        5.570563                                   NaN   \n",
       "89998        5.330000                                   NaN   \n",
       "89999        5.330000                                   NaN   \n",
       "90000        3.500000  247179b0-af1f-4c2b-b4fe-751070d1c0cc   \n",
       "\n",
       "                   spotify_id             genre  \n",
       "89996                     NaN               NaN  \n",
       "89997                     NaN  progressive rock  \n",
       "89998                     NaN               NaN  \n",
       "89999                     NaN               NaN  \n",
       "90000  14BYEOeRb3jzglJmKX8eM2           ambient  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_emotion_tags</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>90001.000000</td>\n",
       "      <td>90001.000000</td>\n",
       "      <td>90001.000000</td>\n",
       "      <td>90001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.987745</td>\n",
       "      <td>5.454280</td>\n",
       "      <td>4.317691</td>\n",
       "      <td>5.246029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.153822</td>\n",
       "      <td>1.553079</td>\n",
       "      <td>1.154948</td>\n",
       "      <td>1.171096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.108113</td>\n",
       "      <td>0.229231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.277500</td>\n",
       "      <td>3.527500</td>\n",
       "      <td>4.550194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>5.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.696667</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>6.115443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>8.475000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>7.440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_emotion_tags  valence_tags  arousal_tags  dominance_tags\n",
       "count            90001.000000  90001.000000  90001.000000    90001.000000\n",
       "mean                 3.987745      5.454280      4.317691        5.246029\n",
       "std                  4.153822      1.553079      1.154948        1.171096\n",
       "min                  1.000000      0.235000      0.108113        0.229231\n",
       "25%                  1.000000      4.277500      3.527500        4.550194\n",
       "50%                  2.000000      5.650000      4.330000        5.460000\n",
       "75%                  5.000000      6.696667      5.150000        6.115443\n",
       "max                 50.000000      8.475000      7.270000        7.440000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando Duplicados\n",
    "\n",
    "Na página onde se encontra a Base de Dados, há um aviso de que se tem uma quantidade significativa de duplicadas. Então, vamos analisar como podemos fazer a limpeza.\n",
    "\n",
    "[Página para a Base de Dados no Kaggle](https://www.kaggle.com/datasets/cakiki/muse-the-musical-sentiment-dataset)\n",
    "\n",
    "Observe, na Base de Dados, que não faz sentido procurar as músicas duplicadas através das colunas: \"seeds\", \"number_of_emotion_tags\", \"valence_tags\", \"arousal_tags\", \"dominance_tags\", \"genre\". Vamos, portanto, analizar as demais colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando duplicados pela coluna \"lastfm_url\"\n",
    "dados.duplicated(\"lastfm_url\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas duplicadas: 28783\n",
      "Número de NaN: 28784\n"
     ]
    }
   ],
   "source": [
    "# verificando duplicados pela coluna \"mbid\"\n",
    "duplicate_mbid = dados[dados.duplicated(\"mbid\")]\n",
    "numero_linhas_duplicadas_mbid = duplicate_mbid.shape[0]\n",
    "print(\"Número de linhas duplicadas:\", numero_linhas_duplicadas_mbid)\n",
    "numero_na_mbid = dados[\"mbid\"].isna().sum()\n",
    "print(\"Número de NaN:\", numero_na_mbid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>mbid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Feedback</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Wollt Ihr Das Bett In Flammen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Hey, Cruel World...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Self vs Self</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Roadblox</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>RAINY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>Battle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>Hands Tied to the Roots of a Hemorrhage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Crookfield Zoo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>Transparent (Full Version)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28783 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         track mbid\n",
       "6                                     Feedback  NaN\n",
       "58               Wollt Ihr Das Bett In Flammen  NaN\n",
       "72                         Hey, Cruel World...  NaN\n",
       "86                                Self vs Self  NaN\n",
       "88                                    Roadblox  NaN\n",
       "...                                        ...  ...\n",
       "89995                                    RAINY  NaN\n",
       "89996                                   Battle  NaN\n",
       "89997  Hands Tied to the Roots of a Hemorrhage  NaN\n",
       "89998                           Crookfield Zoo  NaN\n",
       "89999               Transparent (Full Version)  NaN\n",
       "\n",
       "[28783 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_mbid[[\"track\", \"mbid\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas duplicadas: 10609\n",
      "Número de NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# verificando duplicados pela coluna \"track\"\n",
    "duplicate_track = dados[dados.duplicated(\"track\")]\n",
    "numero_linhas_duplicadas_track = duplicate_track.shape[0]\n",
    "print(\"Número de linhas duplicadas:\", numero_linhas_duplicadas_track)\n",
    "numero_na_track = dados[\"track\"].isna().sum()\n",
    "print(\"Número de NaN:\", numero_na_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Requiem</td>\n",
       "      <td>Avenged Sevenfold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Damage</td>\n",
       "      <td>Non-Prophets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>Down</td>\n",
       "      <td>Pitchshifter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Ruiner</td>\n",
       "      <td>The Body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Blaze</td>\n",
       "      <td>Arsonists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89983</th>\n",
       "      <td>Secret</td>\n",
       "      <td>Quietdrive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89989</th>\n",
       "      <td>Transparent</td>\n",
       "      <td>Porcelain Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89992</th>\n",
       "      <td>Transparent</td>\n",
       "      <td>Second Chyld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>Battle</td>\n",
       "      <td>Gaby Hoffmann &amp; Jay Duplass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000</th>\n",
       "      <td>Unfold</td>\n",
       "      <td>Message To Bears</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10609 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             track                       artist\n",
       "79         Requiem            Avenged Sevenfold\n",
       "306         Damage                 Non-Prophets\n",
       "623           Down                 Pitchshifter\n",
       "783         Ruiner                     The Body\n",
       "786          Blaze                    Arsonists\n",
       "...            ...                          ...\n",
       "89983       Secret                   Quietdrive\n",
       "89989  Transparent              Porcelain Black\n",
       "89992  Transparent                 Second Chyld\n",
       "89996       Battle  Gaby Hoffmann & Jay Duplass\n",
       "90000       Unfold             Message To Bears\n",
       "\n",
       "[10609 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_track[[\"track\", \"artist\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Verificando Duplicados pela coluna \"track\" e \"artist\"\n",
    "duplicate_track_artist = dados[dados.duplicated([\"track\", \"artist\"])]\n",
    "numero_linhas_duplicadas_track_artist = duplicate_track_artist.shape[0]\n",
    "print(numero_linhas_duplicadas_track_artist)\n",
    "numero_na_track = dados[\"track\"].isna().sum()\n",
    "print(numero_na_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas duplicadas: 29344\n",
      "Número de NaN: 28371\n"
     ]
    }
   ],
   "source": [
    "# Verificando Duplicados pela coluna \"spotify_id\"\n",
    "duplicate_spotify_id = dados[dados.duplicated(\"spotify_id\")]\n",
    "numero_linhas_duplicadas_spotify_id = duplicate_spotify_id.shape[0]\n",
    "print(\"Número de linhas duplicadas:\", numero_linhas_duplicadas_spotify_id)\n",
    "numero_na_spotify_id = dados[\"spotify_id\"].isna().sum()\n",
    "print(\"Número de NaN:\", numero_na_spotify_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>spotify_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I'm the One</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I'm Crying</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Thru the Walls</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>It's So Easy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Don't Pray on Me</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>RAINY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>Battle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>Hands Tied to the Roots of a Hemorrhage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>Crookfield Zoo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>Transparent (Full Version)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29344 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         track spotify_id\n",
       "29                                 I'm the One        NaN\n",
       "31                                  I'm Crying        NaN\n",
       "55                              Thru the Walls        NaN\n",
       "56                                It's So Easy        NaN\n",
       "125                           Don't Pray on Me        NaN\n",
       "...                                        ...        ...\n",
       "89995                                    RAINY        NaN\n",
       "89996                                   Battle        NaN\n",
       "89997  Hands Tied to the Roots of a Hemorrhage        NaN\n",
       "89998                           Crookfield Zoo        NaN\n",
       "89999               Transparent (Full Version)        NaN\n",
       "\n",
       "[29344 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_spotify_id[[\"track\",\"spotify_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>spotify_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Come To Daddy, Pappy Mix</td>\n",
       "      <td>53T0V3jTJDs3kIqwvlgspI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Come to Daddy [Pappy Mix]</td>\n",
       "      <td>53T0V3jTJDs3kIqwvlgspI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Blur The Technicolor [Poker From Stud To Strip...</td>\n",
       "      <td>0Kv3NV97Pu1tdPfsifVlWm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Rock N Roll Nigger</td>\n",
       "      <td>5VYVcGgRxhz39ujXLRB42p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>More Human Than Human [Meet Bambi In The King'...</td>\n",
       "      <td>2G3F5LyALgIMFbcCi88oYO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89664</th>\n",
       "      <td>Marduk T-Shirt Men's Room Incident</td>\n",
       "      <td>3fncHAdVqkMaQ2yfOUUCuA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89688</th>\n",
       "      <td>Bigfoot</td>\n",
       "      <td>67yMXB3cMuDWpgSmVlKjCP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89802</th>\n",
       "      <td>MTV - Get off the Air</td>\n",
       "      <td>5wQ6zZPJnqI9DAXv4qcRjL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89823</th>\n",
       "      <td>John, 2,14</td>\n",
       "      <td>4jbhOZFJtvO2gyHxwfhWks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89930</th>\n",
       "      <td>Rainbows (Live '01)</td>\n",
       "      <td>2ubBqnxBNP8QpoGQ77NPuO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   track  \\\n",
       "376                             Come To Daddy, Pappy Mix   \n",
       "409                            Come to Daddy [Pappy Mix]   \n",
       "493    Blur The Technicolor [Poker From Stud To Strip...   \n",
       "531                                   Rock N Roll Nigger   \n",
       "899    More Human Than Human [Meet Bambi In The King'...   \n",
       "...                                                  ...   \n",
       "89664                 Marduk T-Shirt Men's Room Incident   \n",
       "89688                                            Bigfoot   \n",
       "89802                              MTV - Get off the Air   \n",
       "89823                                         John, 2,14   \n",
       "89930                                Rainbows (Live '01)   \n",
       "\n",
       "                   spotify_id  \n",
       "376    53T0V3jTJDs3kIqwvlgspI  \n",
       "409    53T0V3jTJDs3kIqwvlgspI  \n",
       "493    0Kv3NV97Pu1tdPfsifVlWm  \n",
       "531    5VYVcGgRxhz39ujXLRB42p  \n",
       "899    2G3F5LyALgIMFbcCi88oYO  \n",
       "...                       ...  \n",
       "89664  3fncHAdVqkMaQ2yfOUUCuA  \n",
       "89688  67yMXB3cMuDWpgSmVlKjCP  \n",
       "89802  5wQ6zZPJnqI9DAXv4qcRjL  \n",
       "89823  4jbhOZFJtvO2gyHxwfhWks  \n",
       "89930  2ubBqnxBNP8QpoGQ77NPuO  \n",
       "\n",
       "[974 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando as linhas que não são NaN e estão duplicadas\n",
    "\n",
    "duplicate_spotify_id[duplicate_spotify_id[\"spotify_id\"].notna()][[\"track\", \"spotify_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>spotify_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43556</th>\n",
       "      <td>Rainbows</td>\n",
       "      <td>2ubBqnxBNP8QpoGQ77NPuO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89930</th>\n",
       "      <td>Rainbows (Live '01)</td>\n",
       "      <td>2ubBqnxBNP8QpoGQ77NPuO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track              spotify_id\n",
       "43556             Rainbows  2ubBqnxBNP8QpoGQ77NPuO\n",
       "89930  Rainbows (Live '01)  2ubBqnxBNP8QpoGQ77NPuO"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vendo um exemplo de duplicada\n",
    "\n",
    "dados[dados[\"spotify_id\"] == \"2ubBqnxBNP8QpoGQ77NPuO\"][[\"track\", \"spotify_id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão:\n",
    "\n",
    "Coluna \"last_fm\": não vamos conseguir fazer essa filtragem com essa coluna uma vez que não apresenta duplicadas.\n",
    "\n",
    "Coluna \"mbid\": os números de duplicadas e NaN se diferem em uma unidade, o que faz crer que as duplicadas se dão pelos NaN. Assim não podemos usar essa coluna somente para fazer essa filtragem.\n",
    "\n",
    "Coluna \"track\": tem potencial a ser usada para fazer a filtragem. Mas existem músicas de mesmo nome mas de artistas diferente, ou seja, temos que essas músicas são duplicadas, mas na realidade não são.\n",
    "\n",
    "Coluna \"track\" e coluna \"artist\": Observe que temos 0 duplicadas e sabemos que isso é falso, provavelmente as strings que representam os nomes das musicas e/ou dos artistas se diferem. Para usar as coluna \"track\" e \"artist\" para a filtragem seria necessário algum tipo de tratamento nos valores das colunas.\n",
    "\n",
    "Coluna \"spotify_id\": as linhas duplicadas se dão em grande maioria pelos valores das colunas serem NaN, o que não implica estarmos tratando da mesma música. Mas como o número de NaN é diferente do número de linhas duplicadas, podemos entender que as linhas linhas que não possuem NaN como valor mas estão duplicadas são músicas que realmente se repetem na base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza\n",
    "\n",
    "Limpando duplicadas e substituindo NaN por \"unknown\" na coluna \"genre\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linhas onde temos valores que não são NaN e são duplicadas\n",
    "linhas_duplicadas = dados[\"spotify_id\"].notna() & dados.duplicated(subset=[\"spotify_id\"]) \n",
    "\n",
    "# fazendo limpeza\n",
    "dados = dados[~linhas_duplicadas] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas duplicadas: 28370\n",
      "Número de NaN: 28371\n"
     ]
    }
   ],
   "source": [
    "# conferindo limpeza, se a limpeza estiver correta devemos ter o número de linhas duplicadas e o número de NaN diferindo em uma unidade.\n",
    "\n",
    "duplicate_spotify_id = dados[dados.duplicated(\"spotify_id\")]\n",
    "numero_linhas_duplicadas_spotify_id = duplicate_spotify_id.shape[0]\n",
    "print(\"Número de linhas duplicadas:\", numero_linhas_duplicadas_spotify_id)\n",
    "numero_na_spotify_id = dados[\"spotify_id\"].isna().sum()\n",
    "print(\"Número de NaN:\", numero_na_spotify_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substituindo NaN por \"unknown\" na coluna \"genre\"\n",
    "dados[\"genre\"] = dados[\"genre\"].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterações na Base de Dados\n",
    "\n",
    "Adicionando Colunas -> Iremos trocar a coluna \"seeds\" que é a coluna onde os valores são os sentimentos por colunas onde cada coluna é um sentimento, iremos atribuir 1 caso apareça o sentimento na linha correspondente e 0 caso contrário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n",
      "C:\\Users\\Italo\\AppData\\Local\\Temp\\ipykernel_15588\\1071847077.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dados[sentimento] = 0\n"
     ]
    }
   ],
   "source": [
    "# ajustando o formato das strings na coluna \"seeds\"\n",
    "dados[\"seeds\"] = dados[\"seeds\"].str.strip(\"[]\").str.replace(\"'\", \"\").str.split(', ')\n",
    "\n",
    "# conjunto para armazenar todos os sentimentos \n",
    "sentimentos = set()\n",
    "\n",
    "# lista para guardar os sentimentos repetidos\n",
    "sentimentos_que_repetiram = []\n",
    "\n",
    "# Percorrer as listas\n",
    "for lista in dados[\"seeds\"]:\n",
    "    for sentimento in lista:\n",
    "        if sentimento in sentimentos:\n",
    "            sentimentos_que_repetiram.append(sentimento)\n",
    "        else:\n",
    "            sentimentos.add(sentimento)\n",
    "\n",
    "# criando as colunas \n",
    "for sentimento in sentimentos:\n",
    "    dados[sentimento] = 0\n",
    "\n",
    "# preenchendo as colunas \n",
    "for sentimento in sentimentos:\n",
    "    dados[sentimento] = dados[\"seeds\"].apply(lambda lista: 1 if sentimento in lista else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluindo colunas que não usaremos\n",
    "\n",
    "Agora, já tratamos a base, e considerando para o objetivo da análise a ser feita, não precisaremos de algumas colunas, sendo elas: \"lastfm_url\", \"seeds\", \"mbid\", \"spotify_id\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop(columns = [\"lastfm_url\", \"seeds\", \"mbid\", \"spotify_id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>number_of_emotion_tags</th>\n",
       "      <th>valence_tags</th>\n",
       "      <th>arousal_tags</th>\n",
       "      <th>dominance_tags</th>\n",
       "      <th>genre</th>\n",
       "      <th>brittle</th>\n",
       "      <th>celebratory</th>\n",
       "      <th>manic</th>\n",
       "      <th>...</th>\n",
       "      <th>transparent</th>\n",
       "      <th>ebullient</th>\n",
       "      <th>uplifting</th>\n",
       "      <th>mighty</th>\n",
       "      <th>suffocating</th>\n",
       "      <th>theatrical</th>\n",
       "      <th>sensual</th>\n",
       "      <th>raucous</th>\n",
       "      <th>rustic</th>\n",
       "      <th>effervescent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Till I Collapse</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>6</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>5.273125</td>\n",
       "      <td>5.690625</td>\n",
       "      <td>rap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>St. Anger</td>\n",
       "      <td>Metallica</td>\n",
       "      <td>8</td>\n",
       "      <td>3.710000</td>\n",
       "      <td>5.833000</td>\n",
       "      <td>5.427250</td>\n",
       "      <td>metal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speedin'</td>\n",
       "      <td>Rick Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>5.870000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>rap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bamboo Banga</td>\n",
       "      <td>M.I.A.</td>\n",
       "      <td>13</td>\n",
       "      <td>6.555071</td>\n",
       "      <td>5.537214</td>\n",
       "      <td>5.691357</td>\n",
       "      <td>hip-hop</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die MF Die</td>\n",
       "      <td>Dope</td>\n",
       "      <td>7</td>\n",
       "      <td>3.771176</td>\n",
       "      <td>5.348235</td>\n",
       "      <td>5.441765</td>\n",
       "      <td>metal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              track     artist  number_of_emotion_tags  valence_tags  \\\n",
       "0  'Till I Collapse     Eminem                       6      4.550000   \n",
       "1         St. Anger  Metallica                       8      3.710000   \n",
       "2          Speedin'  Rick Ross                       1      3.080000   \n",
       "3      Bamboo Banga     M.I.A.                      13      6.555071   \n",
       "4        Die MF Die       Dope                       7      3.771176   \n",
       "\n",
       "   arousal_tags  dominance_tags    genre  brittle  celebratory  manic  ...  \\\n",
       "0      5.273125        5.690625      rap        0            0      0  ...   \n",
       "1      5.833000        5.427250    metal        0            0      0  ...   \n",
       "2      5.870000        5.490000      rap        0            0      0  ...   \n",
       "3      5.537214        5.691357  hip-hop        0            0      0  ...   \n",
       "4      5.348235        5.441765    metal        0            0      0  ...   \n",
       "\n",
       "   transparent  ebullient  uplifting  mighty  suffocating  theatrical  \\\n",
       "0            0          0          0       0            0           0   \n",
       "1            0          0          0       0            0           0   \n",
       "2            0          0          0       0            0           0   \n",
       "3            0          0          0       0            0           0   \n",
       "4            0          0          0       0            0           0   \n",
       "\n",
       "   sensual  raucous  rustic  effervescent  \n",
       "0        0        0       0             0  \n",
       "1        0        0       0             0  \n",
       "2        0        0       0             0  \n",
       "3        0        0       0             0  \n",
       "4        0        0       0             0  \n",
       "\n",
       "[5 rows x 283 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análises\n",
    "\n",
    "Vamos ver quais são os sentimentos que mais aparecem em geral e quais sentimentos mais aparecem por gênero musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "analise_genero = dados[dados.columns[6:]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>brittle</th>\n",
       "      <th>celebratory</th>\n",
       "      <th>manic</th>\n",
       "      <th>quiet</th>\n",
       "      <th>autumnal</th>\n",
       "      <th>eccentric</th>\n",
       "      <th>cheerful</th>\n",
       "      <th>springlike</th>\n",
       "      <th>messy</th>\n",
       "      <th>...</th>\n",
       "      <th>transparent</th>\n",
       "      <th>ebullient</th>\n",
       "      <th>uplifting</th>\n",
       "      <th>mighty</th>\n",
       "      <th>suffocating</th>\n",
       "      <th>theatrical</th>\n",
       "      <th>sensual</th>\n",
       "      <th>raucous</th>\n",
       "      <th>rustic</th>\n",
       "      <th>effervescent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hip-hop</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>metal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>progressive rock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90000</th>\n",
       "      <td>ambient</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89027 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  genre  brittle  celebratory  manic  quiet  autumnal  \\\n",
       "0                   rap        0            0      0      0         0   \n",
       "1                 metal        0            0      0      0         0   \n",
       "2                   rap        0            0      0      0         0   \n",
       "3               hip-hop        0            0      0      0         0   \n",
       "4                 metal        0            0      0      0         0   \n",
       "...                 ...      ...          ...    ...    ...       ...   \n",
       "89996           unknown        0            0      0      0         0   \n",
       "89997  progressive rock        0            0      0      0         0   \n",
       "89998           unknown        0            0      0      0         0   \n",
       "89999           unknown        0            0      0      0         0   \n",
       "90000           ambient        0            0      0      0         0   \n",
       "\n",
       "       eccentric  cheerful  springlike  messy  ...  transparent  ebullient  \\\n",
       "0              0         0           0      0  ...            0          0   \n",
       "1              0         0           0      0  ...            0          0   \n",
       "2              0         0           0      0  ...            0          0   \n",
       "3              0         0           0      0  ...            0          0   \n",
       "4              0         0           0      0  ...            0          0   \n",
       "...          ...       ...         ...    ...  ...          ...        ...   \n",
       "89996          0         0           0      0  ...            1          0   \n",
       "89997          0         0           0      0  ...            1          0   \n",
       "89998          0         0           0      0  ...            1          0   \n",
       "89999          0         0           0      0  ...            1          0   \n",
       "90000          0         0           0      0  ...            0          0   \n",
       "\n",
       "       uplifting  mighty  suffocating  theatrical  sensual  raucous  rustic  \\\n",
       "0              0       0            0           0        0        0       0   \n",
       "1              0       0            0           0        0        0       0   \n",
       "2              0       0            0           0        0        0       0   \n",
       "3              0       0            0           0        0        0       0   \n",
       "4              0       0            0           0        0        0       0   \n",
       "...          ...     ...          ...         ...      ...      ...     ...   \n",
       "89996          0       0            0           0        0        0       0   \n",
       "89997          0       0            0           0        0        0       0   \n",
       "89998          0       0            0           0        0        0       0   \n",
       "89999          0       0            0           0        0        0       0   \n",
       "90000          0       0            0           0        0        0       0   \n",
       "\n",
       "       effervescent  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "89996             0  \n",
       "89997             0  \n",
       "89998             0  \n",
       "89999             0  \n",
       "90000             0  \n",
       "\n",
       "[89027 rows x 277 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analise_genero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'greater' did not contain a loop with signature matching types (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.StrDType'>) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# vamos ver quais sentimentos mais aparecem\u001b[39;00m\n\u001b[0;32m      2\u001b[0m freq \u001b[39m=\u001b[39m analise_genero\u001b[39m.\u001b[39msum()\n\u001b[1;32m----> 3\u001b[0m freq \u001b[39m=\u001b[39m freq\u001b[39m.\u001b[39;49msort_values(ascending\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:3634\u001b[0m, in \u001b[0;36mSeries.sort_values\u001b[1;34m(self, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   3632\u001b[0m \u001b[39m# GH 35922. Make sorting stable by leveraging nargsort\u001b[39;00m\n\u001b[0;32m   3633\u001b[0m values_to_sort \u001b[39m=\u001b[39m ensure_key_mapped(\u001b[39mself\u001b[39m, key)\u001b[39m.\u001b[39m_values \u001b[39mif\u001b[39;00m key \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 3634\u001b[0m sorted_index \u001b[39m=\u001b[39m nargsort(values_to_sort, kind, \u001b[39mbool\u001b[39;49m(ascending), na_position)\n\u001b[0;32m   3636\u001b[0m \u001b[39mif\u001b[39;00m is_range_indexer(sorted_index, \u001b[39mlen\u001b[39m(sorted_index)):\n\u001b[0;32m   3637\u001b[0m     \u001b[39mif\u001b[39;00m inplace:\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\sorting.py:429\u001b[0m, in \u001b[0;36mnargsort\u001b[1;34m(items, kind, ascending, na_position, key, mask)\u001b[0m\n\u001b[0;32m    427\u001b[0m     non_nans \u001b[39m=\u001b[39m non_nans[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    428\u001b[0m     non_nan_idx \u001b[39m=\u001b[39m non_nan_idx[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 429\u001b[0m indexer \u001b[39m=\u001b[39m non_nan_idx[non_nans\u001b[39m.\u001b[39;49margsort(kind\u001b[39m=\u001b[39;49mkind)]\n\u001b[0;32m    430\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ascending:\n\u001b[0;32m    431\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'greater' did not contain a loop with signature matching types (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.StrDType'>) -> None"
     ]
    }
   ],
   "source": [
    "# vamos ver quais sentimentos mais aparecem\n",
    "freq = analise_genero.sum()\n",
    "freq = freq.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'greater' did not contain a loop with signature matching types (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.StrDType'>) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m contando_sentimentos \u001b[39m=\u001b[39m analise_genero\u001b[39m.\u001b[39msum()\n\u001b[1;32m----> 2\u001b[0m contando_sentimentos \u001b[39m=\u001b[39m contando_sentimentos\u001b[39m.\u001b[39;49msort_values(ascending\u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:3634\u001b[0m, in \u001b[0;36mSeries.sort_values\u001b[1;34m(self, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   3632\u001b[0m \u001b[39m# GH 35922. Make sorting stable by leveraging nargsort\u001b[39;00m\n\u001b[0;32m   3633\u001b[0m values_to_sort \u001b[39m=\u001b[39m ensure_key_mapped(\u001b[39mself\u001b[39m, key)\u001b[39m.\u001b[39m_values \u001b[39mif\u001b[39;00m key \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 3634\u001b[0m sorted_index \u001b[39m=\u001b[39m nargsort(values_to_sort, kind, \u001b[39mbool\u001b[39;49m(ascending), na_position)\n\u001b[0;32m   3636\u001b[0m \u001b[39mif\u001b[39;00m is_range_indexer(sorted_index, \u001b[39mlen\u001b[39m(sorted_index)):\n\u001b[0;32m   3637\u001b[0m     \u001b[39mif\u001b[39;00m inplace:\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\sorting.py:429\u001b[0m, in \u001b[0;36mnargsort\u001b[1;34m(items, kind, ascending, na_position, key, mask)\u001b[0m\n\u001b[0;32m    427\u001b[0m     non_nans \u001b[39m=\u001b[39m non_nans[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    428\u001b[0m     non_nan_idx \u001b[39m=\u001b[39m non_nan_idx[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 429\u001b[0m indexer \u001b[39m=\u001b[39m non_nan_idx[non_nans\u001b[39m.\u001b[39;49margsort(kind\u001b[39m=\u001b[39;49mkind)]\n\u001b[0;32m    430\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ascending:\n\u001b[0;32m    431\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'greater' did not contain a loop with signature matching types (<class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.StrDType'>) -> None"
     ]
    }
   ],
   "source": [
    "contando_sentimentos = analise_genero.sum()\n",
    "contando_sentimentos = contando_sentimentos.sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre           rapmetalraphip-hopmetalmetalhip-hopnu metalsin...\n",
       "brittle                                                        49\n",
       "celebratory                                                    52\n",
       "manic                                                         279\n",
       "quiet                                                         972\n",
       "                                      ...                        \n",
       "theatrical                                                    841\n",
       "sensual                                                       986\n",
       "raucous                                                       109\n",
       "rustic                                                        170\n",
       "effervescent                                                   41\n",
       "Length: 277, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Crie o gráfico de barras\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mbar(df[\u001b[39m'\u001b[39m\u001b[39mCategoria\u001b[39m\u001b[39m'\u001b[39m], df[\u001b[39m'\u001b[39m\u001b[39mValores\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[39m# Adicione rótulos aos eixos e um título\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mCategoria\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Crie o gráfico de barras\n",
    "plt.bar(df['Categoria'], df['Valores'])\n",
    "\n",
    "# Adicione rótulos aos eixos e um título\n",
    "plt.xlabel('Categoria')\n",
    "plt.ylabel('Valores')\n",
    "plt.title('Gráfico de Barras em Ordem Crescente')\n",
    "\n",
    "# Mostre o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFalha ao iniciar o Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.bar(freq, freq.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFalha ao iniciar o Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "freq.plot.bar()\n",
    "plt.xticks(rotation = 45, ha = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'value' must be an instance of str or bytes, not a numpy.int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39;49mhist(freq)\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:2645\u001b[0m, in \u001b[0;36mhist\u001b[1;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[0;32m   2639\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mhist)\n\u001b[0;32m   2640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhist\u001b[39m(\n\u001b[0;32m   2641\u001b[0m         x, bins\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mrange\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, density\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, weights\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2642\u001b[0m         cumulative\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, bottom\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, histtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbar\u001b[39m\u001b[39m'\u001b[39m, align\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmid\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   2643\u001b[0m         orientation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m, rwidth\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, log\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, color\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2644\u001b[0m         label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stacked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2645\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mhist(\n\u001b[0;32m   2646\u001b[0m         x, bins\u001b[39m=\u001b[39;49mbins, \u001b[39mrange\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mrange\u001b[39;49m, density\u001b[39m=\u001b[39;49mdensity, weights\u001b[39m=\u001b[39;49mweights,\n\u001b[0;32m   2647\u001b[0m         cumulative\u001b[39m=\u001b[39;49mcumulative, bottom\u001b[39m=\u001b[39;49mbottom, histtype\u001b[39m=\u001b[39;49mhisttype,\n\u001b[0;32m   2648\u001b[0m         align\u001b[39m=\u001b[39;49malign, orientation\u001b[39m=\u001b[39;49morientation, rwidth\u001b[39m=\u001b[39;49mrwidth, log\u001b[39m=\u001b[39;49mlog,\n\u001b[0;32m   2649\u001b[0m         color\u001b[39m=\u001b[39;49mcolor, label\u001b[39m=\u001b[39;49mlabel, stacked\u001b[39m=\u001b[39;49mstacked,\n\u001b[0;32m   2650\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py:1461\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1460\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1461\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1463\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1464\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1465\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:6712\u001b[0m, in \u001b[0;36mAxes.hist\u001b[1;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[0;32m   6710\u001b[0m \u001b[39mif\u001b[39;00m orientation \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   6711\u001b[0m     convert_units \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_xunits\n\u001b[1;32m-> 6712\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_unit_info([(\u001b[39m\"\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m\"\u001b[39;49m, x[\u001b[39m0\u001b[39;49m])], kwargs),\n\u001b[0;32m   6713\u001b[0m          \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(convert_units, x[\u001b[39m1\u001b[39m:])]\n\u001b[0;32m   6714\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# horizontal\u001b[39;00m\n\u001b[0;32m   6715\u001b[0m     convert_units \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_yunits\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_base.py:2549\u001b[0m, in \u001b[0;36m_AxesBase._process_unit_info\u001b[1;34m(self, datasets, kwargs, convert)\u001b[0m\n\u001b[0;32m   2547\u001b[0m     \u001b[39m# Update from data if axis is already set but no unit is set yet.\u001b[39;00m\n\u001b[0;32m   2548\u001b[0m     \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m axis\u001b[39m.\u001b[39mhave_units():\n\u001b[1;32m-> 2549\u001b[0m         axis\u001b[39m.\u001b[39;49mupdate_units(data)\n\u001b[0;32m   2550\u001b[0m \u001b[39mfor\u001b[39;00m axis_name, axis \u001b[39min\u001b[39;00m axis_map\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   2551\u001b[0m     \u001b[39m# Return if no axis is set.\u001b[39;00m\n\u001b[0;32m   2552\u001b[0m     \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axis.py:1675\u001b[0m, in \u001b[0;36mAxis.update_units\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1673\u001b[0m neednew \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconverter \u001b[39m!=\u001b[39m converter\n\u001b[0;32m   1674\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconverter \u001b[39m=\u001b[39m converter\n\u001b[1;32m-> 1675\u001b[0m default \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconverter\u001b[39m.\u001b[39;49mdefault_units(data, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1676\u001b[0m \u001b[39mif\u001b[39;00m default \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1677\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_units(default)\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\category.py:105\u001b[0m, in \u001b[0;36mStrCategoryConverter.default_units\u001b[1;34m(data, axis)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m# the conversion call stack is default_units -> axis_info -> convert\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m axis\u001b[39m.\u001b[39munits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     axis\u001b[39m.\u001b[39mset_units(UnitData(data))\n\u001b[0;32m    106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     axis\u001b[39m.\u001b[39munits\u001b[39m.\u001b[39mupdate(data)\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\category.py:181\u001b[0m, in \u001b[0;36mUnitData.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_counter \u001b[39m=\u001b[39m itertools\u001b[39m.\u001b[39mcount()\n\u001b[0;32m    180\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(data)\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\category.py:216\u001b[0m, in \u001b[0;36mUnitData.update\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    213\u001b[0m convertible \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[39mfor\u001b[39;00m val \u001b[39min\u001b[39;00m OrderedDict\u001b[39m.\u001b[39mfromkeys(data):\n\u001b[0;32m    215\u001b[0m     \u001b[39m# OrderedDict just iterates over unique values in data.\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     _api\u001b[39m.\u001b[39;49mcheck_isinstance((\u001b[39mstr\u001b[39;49m, \u001b[39mbytes\u001b[39;49m), value\u001b[39m=\u001b[39;49mval)\n\u001b[0;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m convertible:\n\u001b[0;32m    218\u001b[0m         \u001b[39m# this will only be called so long as convertible is True.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m         convertible \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_str_is_convertible(val)\n",
      "File \u001b[1;32mc:\\Users\\Italo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\_api\\__init__.py:93\u001b[0m, in \u001b[0;36mcheck_isinstance\u001b[1;34m(_types, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m     names\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m     names\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m must be an instance of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, not a \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m         k,\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(names[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m names[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     97\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(names) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m names[\u001b[39m0\u001b[39m],\n\u001b[0;32m     98\u001b[0m         type_name(\u001b[39mtype\u001b[39m(v))))\n",
      "\u001b[1;31mTypeError\u001b[0m: 'value' must be an instance of str or bytes, not a numpy.int64"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(freq)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFalha ao iniciar o Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# vamos ver os sentimentos que mais aparecem por gênero\n",
    "\n",
    "dados.genre.unique().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFalha ao iniciar o Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.11.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
